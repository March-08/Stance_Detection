<!--
*** Thanks for checking out this README Template. If you have a suggestion that would
*** make this better, please fork the repo and create a pull request or simply open
*** an issue with the tag "enhancement".
*** Thanks again! Now go create something AMAZING! :D
-->





<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->




<!-- PROJECT LOGO -->
<br />
<p align="center">
  <a href="https://github.com/othneildrew/Best-README-Template">
    <img src="https://github.com/March-08/Stance_Detetion/blob/master/logo.png" alt="Logo" width="80" height="80">
  </a>

  <h3 align="center">UNITOR: combining Transformer-based architectures and TransferLearning for robust Stance Detection</h3>





## Abstact

**English**. This  paper  describes  the  UNI-TOR system that participated to the StanceDetection  in  Italian  tweets  (Sardistance)task  within  the  context  of  EvalIta  2020.UNITOR implements a transformer-basedarchitecture  whose  accuracy  is  improvedby  adopting  a  Transfer  Learning  tech-nique. In particular, this work investigatesthe  possible  contribution  of  three  auxil-iary tasks related to Stance Detection, i.e.,Sentiment Detection, Hate Speech Detec-tion and Irony Detection.  Moreover, UN-ITOR relies on an additional dataset auto-matically downloaded and labeled throughdistant  supervision.    The  UNITOR  sys-tem ranked first in the competition.  Thisconfirms the effectiveness of Transformer-based architectures and the beneficial im-pact of the adopted strategies.

**Italiano** .Questo  lavoro  descrive  UNI-TOR  il  sistema  che  ha  partecipato  alloStance Detection in Italian tweet (SardiS-tance)   task,   nell’ambito   della   compe-tizione  Evalita  2020.UNITOR  imple-menta  un’architettura  neurale  basata  suTransformer,   la   cui   accuratezza   vienemigliorata   adottando   una   tecnica   diTransfer  Learning.    In  particolare,  ven-gono  aggiunti  tre  auxialiary  taks  rela-tivi  ai  task  di  Sentiment  Detection,  HateSpeech Detection e Irony Detection..   In-oltre,  l’addestramento  di  UNITOR  con-sidera  un  insieme  di  dati  aggiuntivi  chesono  scaricati  ed  etichettati  automatica-mente attraverso la tecnica di Distant Su-pervision.   Il  sistema  si  é  classificato  alprimo  posto  nella  competizione,  confer-mando l’efficacia delle architetture basatesu Transformer e il contributo delle strategie adottate.

## 1 Introduction
Stance detection aims at detecting if the author ofa text is in favor of a target topic, or against it (Kre-jzl et al., 2017). In this task, a text pair is generallyconsidered: one text expresses the topic, while theother reflects the author’s judgments.  In a possi-ble variant to such a setting, the topic is implicitwithin an entire document collection over whichthe stance detection is applied.In this work, we will consider this last setting,as defined in the in the Stance Detection in Ital-ian Tweets (SardiStance) task ((Cignarella et al.,2020))  within  the  Evalita  2020  evaluation  cam-paign.   A  set  of  texts  (here  tweets)  is  provided,almost all concerning the same topic, i.e., the Sar-dines Movement1. The goal is to recognize if eachtweet is for or against (or neither) such topic, onlyexploiting textual information.  According to thetask  definition,  this  corresponds  to  the  so-calledTask A. This is quite challenging problem, sinceit  requires  at  the  same  time  to  discover  if  a  textrefers to the target topic and the author’s orienta-tion, only relying on short messages written in avery conversational style.We  present  the  UNITOR  system  participatingto  the  SardiStance  task.The  system  is  basedon a Transformer-based architecture for text clas-sification  (Devlin  et  al.,  2019)  that  is  directlypre-trained over a large-scale document collectionwritten  in  Italian,  namely  UmBERTo.   In  a  nut-shell,  the  adopted  architecture,  which  has  beendemonstrated achieving state-of-the-art results inmany NLP tasks (Devlin et al., 2019) takes in in-put a message and associates it to one of the targetclasses,  which in turn express if the author is in Favourto the Movement, isAgainstit or neu-tral, as represented byNoneclass.Moreover,  due  to  the  task  complexity  and  thesmall size of the dataset, in order to improve thegeneralization capabilities of the neural network,we adopted a Transfer Learning approach (Pan andYang, 2010).  Our main assumption is that StanceDetection is tied to other tasks involving EmotionRecognition (such as Sentiment Analysis or IronyDetection) even though important differences doexist  among  them.   As  a  simplified  example,  letus consider a message such as “I like the SardinesMovement”:   it  clearly  expresses  a  positive  sen-timent,  also  being  in  favour  of  the  target  topic.However,  a  message  such  as  “I  like  the  EvalItacampaign.”  is positive as well but it does not ex-press  any  support  or  opposition  to  the  Sardines.As a consequence, it should be associated to theNoneclass.  We thus speculate that an automaticsystem trained over an auxiliary task (such as Sen-timent Classification) is beneficial, but the trans-fer process must be carefully designed in order toavoid catastrophic forgetting or catastrophic inter-ference problems (Mccloskey and Cohen, 1989).In this work, we investigate the possible contri-bution of three auxiliary tasks involving the recog-nition of emotions according to different settings,i.e., Sentiment Detection and Classification, HateSpeech Detection and Irony Detection.  We adoptthree  different  classifiers  (one  for  each  auxiliarytask) and use them to add additional information tothe tweets provided in the SardiStance dataset. Asan example,  when considering the auxiliary taskinvolving Hate Detection, the corresponding clas-sifier will augment each input tweet by expressingif this expresses hate or not.  After this step,  thefinal classifier is expected to learn the associationbetween messages and the stance categories, “be-ing aware” (with some unavoidable noise) if themessage  expresses  some  sort  of  hate,  irony  andmore generally, sentiment. Finally, we investigatethe  possibility  of  augmenting  the  training  mate-rial by automatically downloading messages andlabeling them through distant supervision (Go etal., 2009).  We first selected few hashtags clearlyin favour (or not) of the target topic to downloadand label a set of set of messages.  Then, in orderto add a set of neutral messages, we selected a setof news titles concerning the Sardines Movement.The UNITOR system ranked first in the com-petition,   suggesting   that   the   combination   of the Transformer-based learning with the adoptedstrategies of Transfer Learning and Data Augmen-tation is beneficial.In the rest of the paper, Section 2 describes theadopted  Tranformers-based  architecture  and  theunderlying our transfer learning approach. In Sec-tion 3, the performance measures of the system arereported while Section 4 derives the conclusions.

## 2 Transformer-based architectures andTransfer Learning for Stance Detection
The UNITOR system implements a Transformer-based architecture (Devlin et al., 2019) describedin  Section  2.1.   The  adopted  auxiliary  tasks  aredescribed in Section 2.2, while our Transfer lean-ing strategy is reported in Section 2.3.  Finally, anautomatic strategy for Data Augmentation is pre-sented in Section 2.4.

### 2.1    Transformer-based Architecture for textclassification
The  approach  proposed  in  (Devlin  et  al.,  2019),namely   Bidirectional   Encoder   Representationsfrom Transformers (BERT) provides a very effec-tive model to pre-train a deep and complex neu-ral  network  over  very  large  scale  of  not  anno-tated  texts  and  to  apply  it  to  a  large  variety  ofNLP  tasks.   The  building  block  of  BERT  is  theTransformer  element  (Vaswani  et  al.,  2017),  anattention-based mechanism that learns contextualrelations  between  words  in  a  text.   In  line  with(Peters  et  al.,  2018),  BERT  provides  a  sentenceembedding (as well as the contextualized lexicalembeddings of words in the sentence) through apre-training stage aiming at the acquisition of anexpressive  and  robust  language  and  text  model.The Transformer reads the entire input sequenceof  words  at  once  and  is  optimized  through  twopre-training tasks.  The first pre-training objectiveis the (masked language modeling) (Devlin et al.,2019). In addition, aNext Sentence Predictiontaskis  used  to  jointly  pre-train  text  embeddings  ableto soundly represent discourse level information.This last objective operates on text-pair represen-tations and aims at modeling relational informa-tion, e.g.  between the consecutive sentences in atext.  On top of the produced embeddings, BERTapplies afine-tuningstage devoted to adapt the en-tire architecture to the targeted task.The fine-tuning process of BERT for sentenceclassification (here adopted) operates on a single texts or text pairs, which can be given in input toBERT, in analogy with a next sentence predictiontask.  The special token[CLS]is used as first el-ement of each input sequence and the embeddingsproduced  by  BERT  are  used  in  input  to  a  linearclassifier  customized  for  the  target  classificationtask.  While the BERT architecture is pre-trainedon large-scale corpora, its fine tuning is generallyobtained by customizing the classifier to the targettask and fine tuning all the network parameters forfew epochs, to avoid catastrophic forgetting.In  (Liu  et  al.,  2019b)  RoBERTa  is  proposedas  a  variant  of  BERT  which  modifies  some  keyhyperparameters,  including  removing  the  next-sentence  pre-training  objective,  and  training  onmore  data,  with  much  larger  mini-batches  andlearning rates.  This allows RoBERTa to improveon the masked language modeling objective com-pared with BERT and leads to better downstreamtask performances.UNITOR is based on a RoBERTa architecturepre-trained  over  Italian  texts:   we  adopted  Um-BERTo2which is pre-trained over a subset of theOSCAR corpus, made of 11 billion tokens.These architectures achieved state-of-the-art re-sults in a wide ranges of NLP task. However, theyalso relies on large scale annotated datasets com-posed of (possibly hundreds) thousands of exam-ples. In order to improve the quality of this archi-tecture in the SardiStance Task with a quite lim-ited dataset, we adopted a simple Transfer Learn-ing strategy by relying on the three auxiliary tasksdescribed in the following section.

### 2.2  Supporting UNITOR through Auxiliarytasks
In this work, we speculate that the complexity ofthe Stance detection task can be reduced if the sys-tem was already aware that an input message ex-press some sort of Sentiment,  Irony or Hate.   Inorder to expose UNITOR to such information, wetrained specific classifiers over dedicated corporamade available in the previous editions of EvalIta,as it follows: **Sentiment  Detection  and  Classification**. This task consists in the automatic detection of subjec-tivity (and the eventual positive or negative polar-ity) in texts (Pang and Lee, 2008).  Even thoughthe  Stance  Detection  is  clearly  different  from  a traditional  task  of  Sentiment  Analysis,  we  spec-ulate  that  they  are  nevertheless  related.    As  anexample,  we  can  suppose  that  the  presence  ofstance  is  more  probable  in  messages  expressingsubjectivity.  We thus considered the setting pro-posed in SENTIPOLC 2016 (Barbieri et al., 2016)where  a  dataset  of  8000  tweets  is  made  avail-able.   For each message,  the presence of subjec-tivity  is  made  explicit  and,  eventually,  the  posi-tive and negative polarity.  The labeling providedin the dataset was slightly modified and mappedto a classification problem over three classes:  allobjective tweets were labeled with the special tag<neutrale>,  the  subjective  and  positive  mes-sages with <positivo> while the negative ones with <negativo>.
**Irony Detection**  We speculate that a robust de-tection of stance requires the recognition of irony,which can even reverse the output of the classifica-tion task, for example a false stance expressed in aironic message.  The objective of Irony Detectionis to detect whether a given message is ironic ornot.  We used the dataset provided IronITA 2018(Cignarella et al., 2018), where a dataset of 4800labeled messages is made available.  We adoptedthe original binary classification task: we mappedthe ironic messages to the <ironico> label and <non ironico> in the other case.
**Hate  Speech  Detection**. Being  against  a  topiccan be often expressed through messages express-ing  also  hate.   We  thus  introduce  also  the  HateSpeech  Detection  task,  which  involves  the  auto-matic  recognition  of  hateful  contents.   We  con-sidered  the  setting  proposed  in  HaSpeeDe  2018(Bosco et al., 2018), where a dataset of 3,000 mes-sages is made available.  We adopted the originalbinary  classification  task:  we  mapped  messagesexpressing hate with the<odio>label and<nonodio>in the other case.
  
### 2.3  Transferring auxiliary tasks in theTransformer-based learning
In order to transfer the information from each aux-iliary  task  into  UNITOR,  we  first  trained  a  spe-cific UmBERTo-based sentence classifier on eachof the datasets described in the previous section.In  each  case,  the  standard  parameters  proposedin (Devlin et al.,  2019) are used to fine-tune the model4. After this training step, the entire SardiS-tance dataset is processed by the three classifiersand the resulting labels are used to “augment” theinput messages.  In particular, these labels gener-ated a sort of new sentence, which is paired withthe corresponding message.The  following  example  shows  how  a  tweet5against the movement is used in input to UNITOR: 
*“[CLS]negativoironicoodio[SEP]#elezioniregionali    Le    Sardine    aiuteranno    asalvare il Paese! #mafammilpiacere Sono propriodei bei perdigiorno falliti![SEP]”*
Consistently  with  (Devlin  et  al.,  2019),  the  firstpseudo-token[CLS]generates  the  embeddingused in input in the final linear classifier.   Then,a  pseudo-sentence  “negativo  ironico  odio”  sug-gests that the message expresses negative polarityand  hate through  the  adoption of  irony.   Finally,between  the[SEP]pseudo-tokens,  the  originalmessage is reported.This particular schema resembles the classifica-tion of text pairs used in relational learning tasks,such as in Textual Entailment (Devlin et al., 2019).The output of the auxiliary classifiers defines a sortof hypothesis, i.e.,this message is negative, ironicand it expresses hate, while the original messageis  the  thesis6.    The  UNITOR  model  is  thus  anUmBERTo-based classifier trained over text pairs,where the first element encode the information de-rived from the auxiliary tasks and the second oneis the original message.  Even though the qualityof this labeling process can introduce noise (dueto incorrectly classified messages) this is expectedto simplify the final training process, by explicitlyproviding  information  about  sentiment,  hate  and irony.

### 2.4 Supporting Stance Detection via DistantSupervision
In order to balance the limited amount of availabledata (especially considering the complexity of thetask)  we  augmented  the  training  material  by  la-beling additional messages via distant supervision We  speculate  that  a  tweet  containing  an  hashtagsuch as#vivalesardine(in English:#ILikeSarine)is  favour  to  target  instead  of  a  tweet  containingfor example#sardinefritte(in English:#friedSar-dine) is against to our target, same concept for neu-tral tweets. Hence we downloaded from the Twitacorpus  (Basile  and  Nissim,  2013)  3,200  tweetsand labeled them via distant supervision.  In par-ticular  the  following  subset  are  derived:   1,500tweets against the movement sinc containing#gat-ticonsalvini;  1,000  tweets  in  favour,  since  con-taining#nessunotocchilesardine,  #iostoconlesar-dine, #unmaredisardine, #vivalesardineor#forza-sardine; 700 neutral messages which are actuallytitles from news, derived by querying “sardine” inGoogle news.In the experimental evaluations discussed in thenext section,  this dataset of “silver” data is sim-ply added to the training material.  To avoid over-fitting, we removed the 90% of the occurrences ofthe hashtags used as query in the new data.

## 3 Result and Discussion
UNITOR  participated  to  the  Task  A  -  TextualStance Detection (Cignarella et al.,  2020) wherethe available dataset is composed by 2,132 tweetsconcerning the Sardines Movement:  1,028 tweetsare against the movement (labelAgainst), 589tweets  in  favour  of  it  (labelFavour)  and  515tweets do not express any stance about the targettopic (labelNone).As  discussed  in  Section  2,  UNITOR  is  basedon  the  UmBERTo  pre-trained  model,  which  re-lies  on  the  RoBERTa  architecture.   For  parame-ter tuning, we adopted a 10-cross fold validation,so that the training material is divided in 10 folds,each split according to 90%-10% proportion. Themodel  is  trained  using  a  standard  Cross-entropyLoss  and  an  ADAM  optimizer  initialized  with  alearning rate set to2·10−5and linearly decreasedduring the training process.  We trained the modelfor5epochs,  using a batch size of32elements.At  test  time,  an  Ensemble  of  such  classifiers  isused:  each message is in fact classified using all10models trained in the different folds and the la-bel suggested by the highest number of classifiersis selected.  In the Task A, we submitted two con-strained runs, i.e., system considering only tweetsfrom the competition, and two unconstrained ones,where additional tweets were acquired and labeledby applying the approach presented in Section 2.2. 
![alt text](https://github.com/March-08/Stance_Detetion/blob/master/table.PNG)
All  models  are  implemented  using  Pytorch7andexperiments were run over Google Colab8.Results are reported in the Table 1.  In particu-lar, it reports the Precision, Recall and F1 resultsobtained  by  the  different  models  with  respect  toeach label. The final rank is obtained by consider-ing the average F1 (F1-avg) between theFavourandAgainstclasses.First of all, the high complexity of this task isconfirmed  by  the  results  obtained  by  the  strongBaseline  method  (the  last  row).   It  is  a  SupportVector  Machine  trained  over  a  simple  Bag-of-Word model (Cignarella et al., 2020) and achievesan average F1 of57.84%, being competitive withmany systems participating to the task and ranking13thover 22 submissions.One important result is obtained by the straightapplication of the UmBERTo model over the orig-inal  messages  (next  to  last  row  in  Table  1).   Infact, this Transformer-based architecture, empow-ered with the Ensemble technique, achieves an av-erage F1 of65.69%:  a system which directly ap-plies an Enseble of UmBERTo-based model wouldhave ranked6thin the competition.We  thus  trained  UmBERTo  by  adopting  theTransfer Learning approach presented in Section2.3  in  the  constrained  setting.   The  adoption  ofall the three auxiliary tasks led to the constrainedsubmission  called  UNITOR_c_2.   Moreover,  weconsidered the training of UmBERTo by consid-ering one auxiliary task at a time.  When consid-ering only the Hate Speech Detection task, betterresults  were  obtained  over  the  development  set,with  respect  to  the  adoption  of  the  other  taskstaken  individually,  i.e.,  Sentiment  Detection  andIrony  Detection9.    Such  a  variant,  called  UNI-TOR_c_1,  considers  tweets  enriched  only  withinformation  derived  by  the  hate  classifier  and  itgenerally shows higher precision with respect to theAgainstclass.   This  suggests  that  a  tweetexpressing  hate  is  more  likely  in  opposition  tothe Sardines Movement.   Both constrained mod-els ranked3rdand2ndin the competition, respec-tively.  These results are impressive as they bothoutperformed of about2%of absolute F1 the stan-dard UmBERTo. Moreover, they confirm the ben-eficial impact of Hate Speech Detection as an aux-iliary task.Finally,  we  augmented  the  training  dataset  byusing  the  additional  data  presented  in  Section2.2.   We  extended  the  training  material  used  totrain UNITOR_c_2 in order to obtain the uncon-strained  submission  called  UNITOR_u_2.    It  isworth  noticing  the  all  three  auxiliary  tasks  wereused in this submission. This led to a performancedrop, i.e.  a66.06%of average F1, which is lowerwith respect to the best opponent system,  whichachieved a66.21%of F1.  It seems that the noiseadded both from the auxiliary tasks and the addi-tional data, negatively impacted the overall qual-ity.  On the contrary, when only the Hate SpeechDetection task is considered (i.e., UNITOR_u_1)additional  data  are  positively  capitalized  by  themodel, achieving the best average F1 score in thecompetition,  i.e.68.53%.   These results suggestthat  the  combination  of  the  Transformer-basedlearning  with  the  adopted  strategies  of  TransferLearning  and  Data  Augmentation  is  highly  ben-eficial, when only Hate is considered.From an error analysis,  it seems that a signif-icant number of incorrect classifications occurredin longer and complex messages, where the topicof  the  stance  is  not  clearly  explicit  nor  capturedby the UmBERTo model, such as in “#carfagna:“io per i liberali che non si affidano a Salvini” e“dalle sardine buone idee”.   Auto-scacco in duemosse. Con la Polverini poi...”10. This message isconsidered to beAgainstwhile the system as-signs the labelNone.  Here, it is very challengingto understand the connection between the “good ideas of the sardines” and the very colloquial ex-pression “Auto-scacco” which can be translated as“own goal”. The same appears in the tweet “’ragaho finalmente capito chi mi ricordava Mattia San-tori, quello delle sardine:  Lodo Guenzi.  (e infattiin quanto a democristianitá stiamo lá)”11whichagain  labeledAgainstbut  classified  asNone.Clearly  the system  is  not able  to  link the  move-ment to its leader nor to the negative opinion aboutbelonging  to  the  Christian  Democrat  Party.   An-other example is the tweet “Dopo avere ascoltato@luigidimaio mi viene in mente una sola parola:grazie. Fiducia nelle sue scelte e immenso rispettoper i grandi risultati ottenuti.   Ora un nuovo in-izio,  con  un  nuovo  entusiamo.    Andiamo  versogli  #statigenerali  con  serietà  e  maturità.   Forza@mov5stelle!”12.  Here the system incorrectly as-signs  theFavourlabel  because  the  tweet  is  infavour of a different movement.

## 4 Conclusions
In  this  work  we  present  the  results  obtained  bythe  UNITOR  system,  which  participated  to  theSardiStance task. UNITOR ranked first in the TaskA, both for constrained and unconstrained runs.This  results  confirm  the  beneficial  impact  ofTransformer  based  architecture  for  text  classifi-cation  also  in  the  Stance  Detection  task.   More-over, we demonstrate the beneficial impact of HateSpeech Detection as an auxiliary task in a TransferLearning setting.  Finally, we empirically demon-strate that the adoption of Distance Supervision isuseful to reduce data sparseness.Future work will apply the above approaches tothe task B within SardiStance.  Moreover, we willinvestigate multi-task learning approaches (Liu etal., 2019a) to capitalize information from auxiliarytasks is a more principled way.

